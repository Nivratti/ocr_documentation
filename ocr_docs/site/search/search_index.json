{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 OCR (optical character recognition) is the use of technology to distinguish printed or handwritten text characters inside digital images of physical documents, such as a scanned paper document. The basic process of OCR involves examining the text of a document and translating the characters into code that can be used for data processing. OCR is sometimes also referred to as text recognition. Used OCR Engines: \u00b6 PaddleOCR EasyOCR MMOCR TesseractOCR We have fine-tuned paddleocr and easyocr models. modules: \u00b6 Image Skew correction Image orientation correction Text detection Text recognition Structured data System Flow: \u00b6","title":"Introduction"},{"location":"#introduction","text":"OCR (optical character recognition) is the use of technology to distinguish printed or handwritten text characters inside digital images of physical documents, such as a scanned paper document. The basic process of OCR involves examining the text of a document and translating the characters into code that can be used for data processing. OCR is sometimes also referred to as text recognition.","title":"Introduction"},{"location":"#used-ocr-engines","text":"PaddleOCR EasyOCR MMOCR TesseractOCR We have fine-tuned paddleocr and easyocr models.","title":"Used OCR Engines:"},{"location":"#modules","text":"Image Skew correction Image orientation correction Text detection Text recognition Structured data","title":"modules:"},{"location":"#system-flow","text":"","title":"System Flow:"},{"location":"dataset_preparation/","text":"","title":"Dataset preparation"},{"location":"installation/","text":"Installation \u00b6 A) Server requirements: \u00b6 Hardware: \u00b6 CPU cores(4 plus) RAM (8 GB plus) SSD storage: 100 GB GPU card(atleast 4GB memory) Software: \u00b6 Ubuntu 18 / Ubuntu 20 CUDA 10.2 / CUDA 11.6 with cuda compiler Python3 Sample result after running nvidia-smi command: \u00b6 Sample result after running nvcc --version command: \u00b6 Installation: \u00b6 From pip package: Unzip OCR zipped file, goto main folder, and run pip install -r requirements.txt Docker: Command to build: sudo docker build . -t ocr:latest Run : sudo docker run -p 5000:5000 --gpus all --init -it ocr","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#a-server-requirements","text":"","title":"A) Server requirements:"},{"location":"installation/#hardware","text":"CPU cores(4 plus) RAM (8 GB plus) SSD storage: 100 GB GPU card(atleast 4GB memory)","title":"Hardware:"},{"location":"installation/#software","text":"Ubuntu 18 / Ubuntu 20 CUDA 10.2 / CUDA 11.6 with cuda compiler Python3","title":"Software:"},{"location":"installation/#sample-result-after-running-nvidia-smi-command","text":"","title":"Sample result after running nvidia-smi command:"},{"location":"installation/#sample-result-after-running-nvcc-version-command","text":"","title":"Sample result after running nvcc --version command:"},{"location":"installation/#installation_1","text":"From pip package: Unzip OCR zipped file, goto main folder, and run pip install -r requirements.txt Docker: Command to build: sudo docker build . -t ocr:latest Run : sudo docker run -p 5000:5000 --gpus all --init -it ocr","title":"Installation:"},{"location":"sample/","text":"","title":"Sample"},{"location":"structured_data/","text":"","title":"Structured data"},{"location":"training/","text":"","title":"Training"},{"location":"dataset_preparation/annotation-tool/","text":"For data labeling purpose we have used PPOCRLabel tool (https://github.com/PaddlePaddle/PaddleOCR/tree/release/2.6/PPOCRLabel). Tool also included in code part. You can either view video tutorial or you can refer doc link for exploring labeling process. Video tutorial link Splitting dataset: \u00b6 Once you are ready with annotations you can export label and recognition result, that we need to split into train, validation and test set for ocr training or fine-tuning. $ sudo systemctl stop liveness_api","title":"Annotation tool"},{"location":"dataset_preparation/annotation-tool/#splitting-dataset","text":"Once you are ready with annotations you can export label and recognition result, that we need to split into train, validation and test set for ocr training or fine-tuning. $ sudo systemctl stop liveness_api","title":"Splitting dataset:"},{"location":"dataset_preparation/dataset_paddleocr_format/","text":"Detection Paddleocr format \u00b6 1. Text detection \u00b6 1.1 PaddleOCR text detection format annotation \u00b6 The annotation file formats supported by the PaddleOCR text detection algorithm are as follows, separated by \"\\t\": \" Image file name Image annotation information encoded by json.dumps\" ch4_test_images/img_61.jpg [{\"transcription\": \"MASA\", \"points\": [[310, 104], [416, 141], [418, 216], [312, 179]]}, {...}] The image annotation after json.dumps() encoding is a list containing multiple dictionaries. The points in the dictionary represent the coordinates (x, y) of the four points of the text box, arranged clockwise from the point at the upper left corner. transcription represents the text of the current text box. When its content is \"###\" it means that the text box is invalid and will be skipped during training. If you want to train PaddleOCR on other datasets, please build the annotation file according to the above format. 1.2 Public dataset \u00b6 dataset Image download link PaddleOCR format annotation download link ICDAR 2015 https://rrc.cvc.uab.es/?ch=4&com=downloads train / test ctw1500 https://paddleocr.bj.bcebos.com/dataset/ctw1500.zip Included in the downloaded image zip total text https://paddleocr.bj.bcebos.com/dataset/total_text.tar Included in the downloaded image zip 1.2.1 ICDAR 2015 \u00b6 The icdar2015 dataset contains train set which has 1000 images obtained with wearable cameras and test set which has 500 images obtained with wearable cameras. The icdar2015 dataset can be downloaded from the link in the table above. Registration is required for downloading. After registering and logging in, download the part marked in the red box in the figure below. And, the content downloaded by Training Set Images should be saved as the folder icdar_c4_train_imgs , and the content downloaded by Test Set Images is saved as the folder ch4_test_images Decompress the downloaded dataset to the working directory, assuming it is decompressed under PaddleOCR/train_data/. Then download the PaddleOCR format annotation file from the table above. PaddleOCR also provides a data format conversion script, which can convert the official website label to the PaddleOCR format. The data conversion tool is in ppocr/utils/gen_label.py , here is the training set as an example: # Convert the label file downloaded from the official website to train_icdar2015_label.txt python gen_label.py --mode=\"det\" --root_path=\"/path/to/icdar_c4_train_imgs/\" \\ --input_path=\"/path/to/ch4_training_localization_transcription_gt\" \\ --output_label=\"/path/to/train_icdar2015_label.txt\" After decompressing the data set and downloading the annotation file, PaddleOCR/train_data/ has two folders and two files, which are: /PaddleOCR/train_data/icdar2015/text_localization/ \u2514\u2500 icdar_c4_train_imgs/ Training data of icdar dataset \u2514\u2500 ch4_test_images/ Testing data of icdar dataset \u2514\u2500 train_icdar2015_label.txt Training annotation of icdar dataset \u2514\u2500 test_icdar2015_label.txt Test annotation of icdar dataset 2. Text recognition \u00b6 2.1 PaddleOCR text recognition format annotation \u00b6 The text recognition algorithm in PaddleOCR supports two data formats: - lmdb is used to train data sets stored in lmdb format, use lmdb_dataset.py to load; - common dataset is used to train data sets stored in text files, use simple_dataset.py to load. If you want to use your own data for training, please refer to the following to organize your data. Training set It is recommended to put the training images in the same folder, and use a txt file (rec_gt_train.txt) to store the image path and label. The contents of the txt file are as follows: Note: by default, the image path and image label are split with \\t, if you use other methods to split, it will cause training error \" Image file name Image annotation \" train_data/rec/train/word_001.jpg \u7b80\u5355\u53ef\u4f9d\u8d56 train_data/rec/train/word_002.jpg \u7528\u79d1\u6280\u8ba9\u590d\u6742\u7684\u4e16\u754c\u66f4\u7b80\u5355 ... The final training set should have the following file structure: |-train_data |-rec |- rec_gt_train.txt |- train |- word_001.png |- word_002.jpg |- word_003.jpg | ... Test set Similar to the training set, the test set also needs to be provided a folder containing all images (test) and a rec_gt_test.txt. The structure of the test set is as follows: |-train_data |-rec |-ic15_data |- rec_gt_test.txt |- test |- word_001.jpg |- word_002.jpg |- word_003.jpg | ... 2.2 Public dataset \u00b6 dataset Image download link PaddleOCR format annotation download link en benchmark(MJ, SJ, IIIT, SVT, IC03, IC13, IC15, SVTP, and CUTE.) DTRB LMDB format, which can be loaded directly with lmdb_dataset.py ICDAR 2015 http://rrc.cvc.uab.es/?ch=4&com=downloads train / test Multilingual datasets Baidu network disk Extraction code: frgi google drive Included in the downloaded image zip 2.1 ICDAR 2015 \u00b6 The ICDAR 2015 dataset can be downloaded from the link in the table above for quick validation. The lmdb format dataset required by en benchmark can also be downloaded from the table above. Then download the PaddleOCR format annotation file from the table above. PaddleOCR also provides a data format conversion script, which can convert the ICDAR official website label to the data format supported by PaddleOCR. The data conversion tool is in ppocr/utils/gen_label.py , here is the training set as an example: # Convert the label file downloaded from the official website to rec_gt_label.txt python gen_label.py --mode=\"rec\" --input_path=\"{path/of/origin/label}\" --output_label=\"rec_gt_label.txt\" The data format is as follows, (a) is the original picture, (b) is the Ground Truth text file corresponding to each picture: 3. Data storage path \u00b6 The default storage path for PaddleOCR training data is PaddleOCR/train_data , if you already have a dataset on your disk, just create a soft link to the dataset directory: # linux and mac os ln -sf <path/to/dataset> <path/to/paddle_ocr>/train_data/dataset # windows mklink /d <path/to/paddle_ocr>/train_data/dataset <path/to/dataset>","title":"Detection Paddleocr format"},{"location":"dataset_preparation/dataset_paddleocr_format/#detection-paddleocr-format","text":"","title":"Detection Paddleocr format"},{"location":"dataset_preparation/dataset_paddleocr_format/#1-text-detection","text":"","title":"1. Text detection"},{"location":"dataset_preparation/dataset_paddleocr_format/#11-paddleocr-text-detection-format-annotation","text":"The annotation file formats supported by the PaddleOCR text detection algorithm are as follows, separated by \"\\t\": \" Image file name Image annotation information encoded by json.dumps\" ch4_test_images/img_61.jpg [{\"transcription\": \"MASA\", \"points\": [[310, 104], [416, 141], [418, 216], [312, 179]]}, {...}] The image annotation after json.dumps() encoding is a list containing multiple dictionaries. The points in the dictionary represent the coordinates (x, y) of the four points of the text box, arranged clockwise from the point at the upper left corner. transcription represents the text of the current text box. When its content is \"###\" it means that the text box is invalid and will be skipped during training. If you want to train PaddleOCR on other datasets, please build the annotation file according to the above format.","title":"1.1 PaddleOCR text detection format annotation"},{"location":"dataset_preparation/dataset_paddleocr_format/#12-public-dataset","text":"dataset Image download link PaddleOCR format annotation download link ICDAR 2015 https://rrc.cvc.uab.es/?ch=4&com=downloads train / test ctw1500 https://paddleocr.bj.bcebos.com/dataset/ctw1500.zip Included in the downloaded image zip total text https://paddleocr.bj.bcebos.com/dataset/total_text.tar Included in the downloaded image zip","title":"1.2 Public dataset"},{"location":"dataset_preparation/dataset_paddleocr_format/#121-icdar-2015","text":"The icdar2015 dataset contains train set which has 1000 images obtained with wearable cameras and test set which has 500 images obtained with wearable cameras. The icdar2015 dataset can be downloaded from the link in the table above. Registration is required for downloading. After registering and logging in, download the part marked in the red box in the figure below. And, the content downloaded by Training Set Images should be saved as the folder icdar_c4_train_imgs , and the content downloaded by Test Set Images is saved as the folder ch4_test_images Decompress the downloaded dataset to the working directory, assuming it is decompressed under PaddleOCR/train_data/. Then download the PaddleOCR format annotation file from the table above. PaddleOCR also provides a data format conversion script, which can convert the official website label to the PaddleOCR format. The data conversion tool is in ppocr/utils/gen_label.py , here is the training set as an example: # Convert the label file downloaded from the official website to train_icdar2015_label.txt python gen_label.py --mode=\"det\" --root_path=\"/path/to/icdar_c4_train_imgs/\" \\ --input_path=\"/path/to/ch4_training_localization_transcription_gt\" \\ --output_label=\"/path/to/train_icdar2015_label.txt\" After decompressing the data set and downloading the annotation file, PaddleOCR/train_data/ has two folders and two files, which are: /PaddleOCR/train_data/icdar2015/text_localization/ \u2514\u2500 icdar_c4_train_imgs/ Training data of icdar dataset \u2514\u2500 ch4_test_images/ Testing data of icdar dataset \u2514\u2500 train_icdar2015_label.txt Training annotation of icdar dataset \u2514\u2500 test_icdar2015_label.txt Test annotation of icdar dataset","title":"1.2.1 ICDAR 2015"},{"location":"dataset_preparation/dataset_paddleocr_format/#2-text-recognition","text":"","title":"2. Text recognition"},{"location":"dataset_preparation/dataset_paddleocr_format/#21-paddleocr-text-recognition-format-annotation","text":"The text recognition algorithm in PaddleOCR supports two data formats: - lmdb is used to train data sets stored in lmdb format, use lmdb_dataset.py to load; - common dataset is used to train data sets stored in text files, use simple_dataset.py to load. If you want to use your own data for training, please refer to the following to organize your data. Training set It is recommended to put the training images in the same folder, and use a txt file (rec_gt_train.txt) to store the image path and label. The contents of the txt file are as follows: Note: by default, the image path and image label are split with \\t, if you use other methods to split, it will cause training error \" Image file name Image annotation \" train_data/rec/train/word_001.jpg \u7b80\u5355\u53ef\u4f9d\u8d56 train_data/rec/train/word_002.jpg \u7528\u79d1\u6280\u8ba9\u590d\u6742\u7684\u4e16\u754c\u66f4\u7b80\u5355 ... The final training set should have the following file structure: |-train_data |-rec |- rec_gt_train.txt |- train |- word_001.png |- word_002.jpg |- word_003.jpg | ... Test set Similar to the training set, the test set also needs to be provided a folder containing all images (test) and a rec_gt_test.txt. The structure of the test set is as follows: |-train_data |-rec |-ic15_data |- rec_gt_test.txt |- test |- word_001.jpg |- word_002.jpg |- word_003.jpg | ...","title":"2.1 PaddleOCR text recognition format annotation"},{"location":"dataset_preparation/dataset_paddleocr_format/#22-public-dataset","text":"dataset Image download link PaddleOCR format annotation download link en benchmark(MJ, SJ, IIIT, SVT, IC03, IC13, IC15, SVTP, and CUTE.) DTRB LMDB format, which can be loaded directly with lmdb_dataset.py ICDAR 2015 http://rrc.cvc.uab.es/?ch=4&com=downloads train / test Multilingual datasets Baidu network disk Extraction code: frgi google drive Included in the downloaded image zip","title":"2.2 Public dataset"},{"location":"dataset_preparation/dataset_paddleocr_format/#21-icdar-2015","text":"The ICDAR 2015 dataset can be downloaded from the link in the table above for quick validation. The lmdb format dataset required by en benchmark can also be downloaded from the table above. Then download the PaddleOCR format annotation file from the table above. PaddleOCR also provides a data format conversion script, which can convert the ICDAR official website label to the data format supported by PaddleOCR. The data conversion tool is in ppocr/utils/gen_label.py , here is the training set as an example: # Convert the label file downloaded from the official website to rec_gt_label.txt python gen_label.py --mode=\"rec\" --input_path=\"{path/of/origin/label}\" --output_label=\"rec_gt_label.txt\" The data format is as follows, (a) is the original picture, (b) is the Ground Truth text file corresponding to each picture:","title":"2.1 ICDAR 2015"},{"location":"dataset_preparation/dataset_paddleocr_format/#3-data-storage-path","text":"The default storage path for PaddleOCR training data is PaddleOCR/train_data , if you already have a dataset on your disk, just create a soft link to the dataset directory: # linux and mac os ln -sf <path/to/dataset> <path/to/paddle_ocr>/train_data/dataset # windows mklink /d <path/to/paddle_ocr>/train_data/dataset <path/to/dataset>","title":"3. Data storage path"}]}